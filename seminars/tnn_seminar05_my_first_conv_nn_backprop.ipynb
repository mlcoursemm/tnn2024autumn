{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50470a6b-4b1f-4c22-8ef5-00bf345a4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Реализовать для всех слоёв (кроме свёрток) и лосс функции метод grad_x\n",
    "2. Реализовать для класса сети функцию grad_x\n",
    "3. Покрыть тестами\n",
    "4. Реализовать grad_params для DenseLayer, Conv (опционально), TransposeConv (опционально)\n",
    "5. Реализовать метод partial_fit для класса NeuralNetwork\n",
    "6. Реализовать оптимизатор SGD, реализовать momentum (опционально), реализовать NAG (опционально)\n",
    "7. (опционально) Реализовать BatchNorm, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81381f34-f363-4c8f-9986-f790e060ffaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, loss):\n",
    "        self.layers = layers\n",
    "        self.loss = loss\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        result = x\n",
    "        for layer in layers:\n",
    "            result = layer.forward(result)\n",
    "        return result\n",
    "    \n",
    "    def grad_x(self, x, labels):\n",
    "        # forward\n",
    "        results = [x]\n",
    "        result = x\n",
    "        for layer in layers:\n",
    "            result = layer.forward(result)\n",
    "            results.append(result) \n",
    "        # L = self.loss(result, labels)\n",
    "        dL = self.loss.grad_x(result, lables)\n",
    "        \n",
    "        for i in range(len(layers) - 1, 0, -1):\n",
    "            dL = layers[i].grad_x(results[i], dL)\n",
    "        return dL\n",
    "    \n",
    "    def partial_fit(self, x, labels, optimizer):\n",
    "        pass\n",
    "    \n",
    "class Layer:\n",
    "    def __init__(self, ):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    \n",
    "    def backward(self, x, dL):\n",
    "        return self.grad_x(x, dL), self.grad_params(x)\n",
    "    \n",
    "    def grad_x(self, x, dL):\n",
    "        pass\n",
    "    \n",
    "    def grad_params(self, x, dL):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1f83c1-6017-4688-be5b-720ec063808b",
   "metadata": {},
   "source": [
    "$ y = W \\cdot x + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e666b91b-7fde-4814-8ccb-24a4c6349712",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer: # Fully Connected Layer\n",
    "    def __init__(self, input_length, output_length, W=None, b=None):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    \n",
    "class ReLU():\n",
    "    def __init__(self, ):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return np.max(0, x)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "class Softmax():\n",
    "    def __init__(self, ):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    \n",
    "class Flatten():\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f981cd2-34b0-4197-8557-feeda9199026",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv():\n",
    "    def __init__(self, input_channels, output_channels, kernel_size=(3,3), padding=0, stride=(1,1), weights=None, bias=None):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "def conv2matrix(input_size, conv_weights):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ff20a-8d60-436a-96f0-8b4d88a1dd47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8574e048-33ed-4bbb-a932-09989b5e7f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input is an image 28x28\n",
    "layer0 = Flatten()\n",
    "layer1 = DenseLayer(784, 500)\n",
    "layer2 = ReLU()\n",
    "layer3 = DenseLayer(500, 100)\n",
    "layer4 = ReLU()\n",
    "layer5 = DenseLayer(100, 10)\n",
    "layer6 = Softmax()\n",
    "\n",
    "layers = [layer1, layer2, layer3, layer4, layer5, layer6]\n",
    "\n",
    "net = NeuralNetwork(layers)\n",
    "\n",
    "x = ...\n",
    "\n",
    "y = net(x) # net.forward(x)\n",
    "\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f7900d-c76a-4d3d-ab82-592955bb63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test(net, test_dataset):\n",
    "    total_right_preds = 0\n",
    "    for batch_x, batch_y in test_dataset:\n",
    "        pred = net.forward(batch_x)\n",
    "        total_right_preds += compare_pred_and_gt(pred, batch_y)\n",
    "    return total_right_preds/len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6021a811-c834-42f2-bb08-47f3dadc738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_path = ''\n",
    "batch_size = 64\n",
    "mnist_train_dataset, mnist_test_dataset = Dataset(mnist_path, batch_size)\n",
    "\n",
    "n_epochs = 100\n",
    "learning_rate = 0.0001\n",
    "\n",
    "optimizer = MySGD(learning_rate)\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    for batch_x, batch_y in mnist_train_dataset:\n",
    "        net.partial_fit(batch_x, batch_y, optimizer)\n",
    "    \n",
    "    current_accuracy = make_test(net, mnist_test_dataset)\n",
    "    print(f'Epoch {i}: acc={current_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a348e615-f81b-4403-b71d-ed6f64d85e83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
